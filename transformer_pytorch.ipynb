{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd8UUDbPw0EZCkxwc2Zno4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanujsriv/_transformer_models_/blob/main/transformer_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model, eps=1e-12):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
        "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        var = x.var(-1, unbiased=False, keepdim=True)\n",
        "        # '-1' means last dimension.\n",
        "\n",
        "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        out = self.gamma * out + self.beta\n",
        "        return out"
      ],
      "metadata": {
        "id": "vBNj5PE5Fbmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwABSi-h8dXr",
        "outputId": "7f3ea33a-d161-43e7-f1eb-e9b9107dc4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformer'...\n",
            "remote: Enumerating objects: 994, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/268)\u001b[K\rremote: Counting objects:   1% (3/268)\u001b[K\rremote: Counting objects:   2% (6/268)\u001b[K\rremote: Counting objects:   3% (9/268)\u001b[K\rremote: Counting objects:   4% (11/268)\u001b[K\rremote: Counting objects:   5% (14/268)\u001b[K\rremote: Counting objects:   6% (17/268)\u001b[K\rremote: Counting objects:   7% (19/268)\u001b[K\rremote: Counting objects:   8% (22/268)\u001b[K\rremote: Counting objects:   9% (25/268)\u001b[K\rremote: Counting objects:  10% (27/268)\u001b[K\rremote: Counting objects:  11% (30/268)\u001b[K\rremote: Counting objects:  12% (33/268)\u001b[K\rremote: Counting objects:  13% (35/268)\u001b[K\rremote: Counting objects:  14% (38/268)\u001b[K\rremote: Counting objects:  15% (41/268)\u001b[K\rremote: Counting objects:  16% (43/268)\u001b[K\rremote: Counting objects:  17% (46/268)\u001b[K\rremote: Counting objects:  18% (49/268)\u001b[K\rremote: Counting objects:  19% (51/268)\u001b[K\rremote: Counting objects:  20% (54/268)\u001b[K\rremote: Counting objects:  21% (57/268)\u001b[K\rremote: Counting objects:  22% (59/268)\u001b[K\rremote: Counting objects:  23% (62/268)\u001b[K\rremote: Counting objects:  24% (65/268)\u001b[K\rremote: Counting objects:  25% (67/268)\u001b[K\rremote: Counting objects:  26% (70/268)\u001b[K\rremote: Counting objects:  27% (73/268)\u001b[K\rremote: Counting objects:  28% (76/268)\u001b[K\rremote: Counting objects:  29% (78/268)\u001b[K\rremote: Counting objects:  30% (81/268)\u001b[K\rremote: Counting objects:  31% (84/268)\u001b[K\rremote: Counting objects:  32% (86/268)\u001b[K\rremote: Counting objects:  33% (89/268)\u001b[K\rremote: Counting objects:  34% (92/268)\u001b[K\rremote: Counting objects:  35% (94/268)\u001b[K\rremote: Counting objects:  36% (97/268)\u001b[K\rremote: Counting objects:  37% (100/268)\u001b[K\rremote: Counting objects:  38% (102/268)\u001b[K\rremote: Counting objects:  39% (105/268)\u001b[K\rremote: Counting objects:  40% (108/268)\u001b[K\rremote: Counting objects:  41% (110/268)\u001b[K\rremote: Counting objects:  42% (113/268)\u001b[K\rremote: Counting objects:  43% (116/268)\u001b[K\rremote: Counting objects:  44% (118/268)\u001b[K\rremote: Counting objects:  45% (121/268)\u001b[K\rremote: Counting objects:  46% (124/268)\u001b[K\rremote: Counting objects:  47% (126/268)\u001b[K\rremote: Counting objects:  48% (129/268)\u001b[K\rremote: Counting objects:  49% (132/268)\u001b[K\rremote: Counting objects:  50% (134/268)\u001b[K\rremote: Counting objects:  51% (137/268)\u001b[K\rremote: Counting objects:  52% (140/268)\u001b[K\rremote: Counting objects:  53% (143/268)\u001b[K\rremote: Counting objects:  54% (145/268)\u001b[K\rremote: Counting objects:  55% (148/268)\u001b[K\rremote: Counting objects:  56% (151/268)\u001b[K\rremote: Counting objects:  57% (153/268)\u001b[K\rremote: Counting objects:  58% (156/268)\u001b[K\rremote: Counting objects:  59% (159/268)\u001b[K\rremote: Counting objects:  60% (161/268)\u001b[K\rremote: Counting objects:  61% (164/268)\u001b[K\rremote: Counting objects:  62% (167/268)\u001b[K\rremote: Counting objects:  63% (169/268)\u001b[K\rremote: Counting objects:  64% (172/268)\u001b[K\rremote: Counting objects:  65% (175/268)\u001b[K\rremote: Counting objects:  66% (177/268)\u001b[K\rremote: Counting objects:  67% (180/268)\u001b[K\rremote: Counting objects:  68% (183/268)\u001b[K\rremote: Counting objects:  69% (185/268)\u001b[K\rremote: Counting objects:  70% (188/268)\u001b[K\rremote: Counting objects:  71% (191/268)\u001b[K\rremote: Counting objects:  72% (193/268)\u001b[K\rremote: Counting objects:  73% (196/268)\u001b[K\rremote: Counting objects:  74% (199/268)\u001b[K\rremote: Counting objects:  75% (201/268)\u001b[K\rremote: Counting objects:  76% (204/268)\u001b[K\rremote: Counting objects:  77% (207/268)\u001b[K\rremote: Counting objects:  78% (210/268)\u001b[K\rremote: Counting objects:  79% (212/268)\u001b[K\rremote: Counting objects:  80% (215/268)\u001b[K\rremote: Counting objects:  81% (218/268)\u001b[K\rremote: Counting objects:  82% (220/268)\u001b[K\rremote: Counting objects:  83% (223/268)\u001b[K\rremote: Counting objects:  84% (226/268)\u001b[K\rremote: Counting objects:  85% (228/268)\u001b[K\rremote: Counting objects:  86% (231/268)\u001b[K\rremote: Counting objects:  87% (234/268)\u001b[K\rremote: Counting objects:  88% (236/268)\u001b[K\rremote: Counting objects:  89% (239/268)\u001b[K\rremote: Counting objects:  90% (242/268)\u001b[K\rremote: Counting objects:  91% (244/268)\u001b[K\rremote: Counting objects:  92% (247/268)\u001b[K\rremote: Counting objects:  93% (250/268)\u001b[K\rremote: Counting objects:  94% (252/268)\u001b[K\rremote: Counting objects:  95% (255/268)\u001b[K\rremote: Counting objects:  96% (258/268)\u001b[K\rremote: Counting objects:  97% (260/268)\u001b[K\rremote: Counting objects:  98% (263/268)\u001b[K\rremote: Counting objects:  99% (266/268)\u001b[K\rremote: Counting objects: 100% (268/268)\u001b[K\rremote: Counting objects: 100% (268/268), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 994 (delta 162), reused 160 (delta 160), pack-reused 726 (from 1)\u001b[K\n",
            "Receiving objects: 100% (994/994), 2.01 MiB | 23.13 MiB/s, done.\n",
            "Resolving deltas: 100% (610/610), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hyunwoongko/transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/transformer/models/model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgZNE87G8lo9",
        "outputId": "cddd50fe-bcef-4c3d-e87c-f3043d5a61f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformer/models/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mo9kA6vGPAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from models.model.decoder import Decoder\n",
        "from models.model.encoder import Encoder\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,\n",
        "                 ffn_hidden, n_layers, drop_prob, device):\n",
        "        super().__init__()\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.trg_sos_idx = trg_sos_idx\n",
        "        self.device = device\n",
        "        self.encoder = Encoder(d_model=d_model,\n",
        "                               n_head=n_head,\n",
        "                               max_len=max_len,\n",
        "                               ffn_hidden=ffn_hidden,\n",
        "                               enc_voc_size=enc_voc_size,\n",
        "                               drop_prob=drop_prob,\n",
        "                               n_layers=n_layers,\n",
        "                               device=device)\n",
        "\n",
        "        self.decoder = Decoder(d_model=d_model,\n",
        "                               n_head=n_head,\n",
        "                               max_len=max_len,\n",
        "                               ffn_hidden=ffn_hidden,\n",
        "                               dec_voc_size=dec_voc_size,\n",
        "                               drop_prob=drop_prob,\n",
        "                               n_layers=n_layers,\n",
        "                               device=device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        return output\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        return trg_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwWrs0ob-Fzd",
        "outputId": "6f38c8ec-17e3-450a-9a20-320ec7ee3bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/transformer/models/model/transformer.py\", line 9, in <module>\n",
            "    from models.model.decoder import Decoder\n",
            "ModuleNotFoundError: No module named 'models'\n"
          ]
        }
      ]
    }
  ]
}